# Provider Configuration
provider:
  name: "openrouter"  # Options: "openrouter", "mistralai", "sambanova", "cerebras", "ollama", "groq"
  # Default model for each provider will be used if not specified

# Provider-specific configurations
openrouter:
  api_key: "API_KEY_HERE"
  base_url: "https://openrouter.ai/api/v1"
  
  # IMPORTANT: When selecting a model, ensure it has a high context window (200k+ tokens recommended)
  # The orchestrator can generate large amounts of results from multiple agents that need to be
  # processed together during synthesis. Low context window models may fail or truncate results.
  model: "moonshotai/kimi-k2"
  # model: "qwen/qwen3-235b-a22b:free"

mistralai:
  api_key: "API_KEY_HERE"
  base_url: "https://api.mistral.ai/v1"
  model: "mistral-large-latest"

sambanova:
  api_key: "API_KEY_HERE"
  base_url: "https://api.sambanova.ai/v1"
  model: "DeepSeek-V3-0324"

cerebras:
  api_key: "API_KEY_HERE"
  model: "llama-4-maverick-17b-128e-instruct"  # Options: llama3.1-8b, llama3.1-70b

ollama:
  base_url: "http://localhost:11434"  # Default Ollama server URL
  model: "qwen3:latest"  # Your preferred model (keeping as requested) [model needs to support tools]
  use_nothink: true  # Send /nothink command to disable thinking process and save resources
  native_tools: true  # Use Ollama's native tool calling support when available
  simulate_tool_calls: false  # Fallback heuristic tool calling for models without native support
  connect_timeout: 15  # HTTP connection timeout in seconds
  timeout_seconds: 300  # Response timeout in seconds
  
  # Response generation options
  temperature: 0.7      # Creativity level (0.0-1.0)
  top_p: 0.9           # Nucleus sampling (0.0-1.0)
  num_ctx: 26192        # Context window size (increased for longer responses)
  num_predict: -1      # Max response tokens (-1 = no limit, let model decide when to stop)
  stop: []             # Custom stop sequences (empty = use model defaults)
  
  # Recommended models for speed: phi3:mini, llama3.1:8b, mistral:7b
  # Large models like qwen3:latest may timeout - use smaller models for better performance

groq:
  api_key: "API_KEY_HERE"
  model: "llama-3.3-70b-versatile"
  temperature: 0.8      # Creativity level (0.0-1.0)
  max_tokens: 8192      # Increased for better responses
  top_p: 1.0            # Nucleus sampling (0.0-1.0)

# System prompt for the agent
system_prompt: |
  You are a helpful research assistant. Your goal is to provide deep, comprehensive answers.
  When users ask for information that may require up-to-date facts, use available tools
  (especially web search) to gather evidence, cross-check claims, and produce a high-quality
  synthesized response.
  
  IMPORTANT TOOL CALLING RULES:
  - When using tools, ONLY use the structured function calling interface
  - NEVER write tool calls as text like <function=name{}> - this will cause errors
  - Always use the proper tool calling mechanism provided by the system
  
  WORKFLOW:
  1. Understand the user's request and determine what must be researched
  2. Use tools as needed to gather and validate information
  3. Provide a comprehensive response grounded in gathered evidence
  4. ONLY call mark_task_complete when the user's request has been fully satisfied
     and your answer is complete

  STYLE:
  - Avoid repeating the same point multiple times
  - Keep the final answer structured and concise
  - If uncertainty exists, explicitly mention it

  IMPORTANT: Do not call mark_task_complete early. Use it only when you are truly done.

# Agent settings
agent:
  max_iterations: 10
  finalize_after_no_tool_streak: 2

# Orchestrator settings
orchestrator:
  parallel_agents: 4  # Number of agents to run in parallel
  task_timeout: 1000   # Timeout in seconds per agent (increased for local models)
  aggregation_strategy: "consensus"  # How to combine results
  
  # Question generation prompt for orchestrator
  question_generation_prompt: |
    You are an orchestrator that needs to create {num_agents} different questions
    to analyze a user topic from multiple angles.
    
    Original user query: {user_input}
    
    Generate exactly {num_agents} specific research questions that cover different perspectives,
    such as background, analysis, alternatives, and verification.

    Each question should:
    1. Be specific and answerable
    2. Approach the topic from a different angle
    3. Help produce a comprehensive final answer

    Return your response as a JSON array of strings, like:
    ["question 1", "question 2", "question 3", "question 4"]
    
    Only return the JSON array, nothing else.

  # Synthesis prompt for combining all agent responses
  synthesis_prompt: |
    You have {num_responses} different AI agents that analyzed the same user query
    from different perspectives.
    Your job is to synthesize their responses into one comprehensive final answer.
    
    Here are the agent responses:
    
    {agent_responses}
    
    Produce a final answer that:
    1. Merges the strongest points from all responses
    2. Resolves conflicts where possible
    3. Is clear, structured, and directly useful to the user

    Do NOT call mark_task_complete or any tools.
    Do NOT mention the synthesis process or individual agents.
    Just provide the final synthesized answer directly.

# Search tool settings
search:
  max_results: 5
  user_agent: "Mozilla/5.0 (compatible; OpenRouter Agent)"
